{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports are necessary for all three stages below, but each stage should be able to be run given that the previous stage has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "import datetime\n",
    "\n",
    "from youtube_dl import YoutubeDL\n",
    "\n",
    "from movie_data_scraper import TMDB_Scraper\n",
    "\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from apiclient.discovery import build\n",
    "from apiclient.http import MediaFileUpload\n",
    "from apiclient import errors\n",
    "\n",
    "yt_url_prefix = 'https://www.youtube.com/watch?v='\n",
    "output_folder = 'data/'\n",
    "tmdb_scraper = TMDB_Scraper(api_key=\"abd17a9f250807b76ebbfa9997ca6ade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Find Movie Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a preliminary search of the results we want to aggregate using tMDb discover API, storing the total number of pages so we can aggregate all of them by iterating later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discover_query_results = tmdb_scraper.run_api(\"discover/movie\", js_query_args={\n",
    "    'sort_by': 'vote_average.desc',\n",
    "    'vote_count.gte': 2000\n",
    "})\n",
    "num_pages = discover_query_results['total_pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through and aggregate all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_movie_ids(cache_file=None):\n",
    "    \"\"\"Get the TMDb trailer IDs of the movies we want to analyze. Currently, the default setting collects\n",
    "    highest rated movies. The optional cache_file argument will allow the user to, instead of collecting the\n",
    "    most up-to-date information, use a cached and dated version.\"\"\"\n",
    "    if cache_file:\n",
    "        return np.load(get_tmdb_cache_path(cache_file))\n",
    "    else:\n",
    "        trailer_ids = []\n",
    "        for p in range(1, num_pages+1):\n",
    "            this_page_results = tmdb_scraper.run_api(\"discover/movie\", js_query_args={\n",
    "                'sort_by': 'vote_average.desc',\n",
    "                'vote_count.gte': 2000,\n",
    "                'page': p\n",
    "            })\n",
    "            print(f\"Aggregating movie IDs from page {p} of {num_pages}\", end='\\r')\n",
    "            trailer_ids.extend(m['id'] for m in this_page_results['results'])\n",
    "        return np.array(trailer_ids)\n",
    "        \n",
    "def get_tmdb_cache_path(cache_file):\n",
    "    return output_folder + 'tmdb_id_history/' + cache_file + \".npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_ids = get_movie_ids('2019-10-30_01-28-00')\n",
    "#tmdb_ids = get_trailer_ids() # Use this line instead to get new, current data for new analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save these TMDb id's with current datetime.\n",
    "# np.save(get_tmdb_cache_path(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")), tmdb_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Aggregate Movie Metadata, Crew Metadata, and Trailer Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect Data in-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating data from of movie 1186 of 1187\r"
     ]
    }
   ],
   "source": [
    "# Make Blank DataFrame to append results to\n",
    "all_trailers = pd.DataFrame({\"tmdb_id\": [], 'tmdb_title': [], \"trailer_title\": [], \"trailer_youtube_key\": []})\n",
    "# Make empty json's to append results to\n",
    "movie_details = {}\n",
    "movie_crew = {}\n",
    "\n",
    "for i, tmdb_id in enumerate(tmdb_ids):\n",
    "    print(f\"Aggregating data from of movie {i} of {len(tmdb_ids)}\", end='\\r')\n",
    "    this_movie_details = tmdb_scraper.movie_details(tmdb_id)\n",
    "    movie_details[str(tmdb_id)] = this_movie_details\n",
    "    movie_crew[str(tmdb_id)] = tmdb_scraper.movie_crew(tmdb_id)\n",
    "    videos = tmdb_scraper.movie_videos(tmdb_id)\n",
    "    trailers = [v for v in videos['results'] if v['type'] == 'Trailer']\n",
    "    for t in trailers:\n",
    "        all_trailers = all_trailers.append({\n",
    "            \"tmdb_id\": this_movie_details['id'],\n",
    "            'tmdb_title': this_movie_details['title'],\n",
    "            'trailer_title': t['name'],\n",
    "            'trailer_youtube_key': t['key']\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trailers.to_csv(osp.join(output_folder, \"trailers.csv\"))\n",
    "with open(osp.join(output_folder, 'movie_details.json'), 'w') as outfile:\n",
    "    json.dump(movie_details, outfile)\n",
    "\n",
    "with open(osp.join(output_folder, 'movie_crew.json'), 'w') as outfile:\n",
    "    json.dump(movie_crew, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Download Movie Trailers to Local Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(output_folder, 'movie_details.json'), 'r') as outfile:\n",
    "    movie_details = json.load(outfile)\n",
    "\n",
    "with open(osp.join(output_folder, 'movie_crew.json'), 'r') as outfile:\n",
    "    movie_crew = json.load(outfile)\n",
    "    \n",
    "trailers = pd.read_csv(osp.join(output_folder, 'trailers.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_trailers(dataset_dir, ydl_opts={}, verbose=False):\n",
    "    ydl_opts['outtmpl'] = dataset_dir + '%(id)s.%(ext)s'\n",
    "    downloaded = os.listdir(dataset_dir)\n",
    "    downloaded = [d.split('.')[0] for d in downloaded]\n",
    "    downloaded = set(downloaded)\n",
    "    all_to_download = set(trailers['trailer_youtube_key'])\n",
    "    remaining_trailers = all_to_download - downloaded\n",
    "    if verbose:\n",
    "        print(f'remaining trailers (len({len(remaining_trailers)})) {remaining_trailers}')\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        for t in remaining_trailers:\n",
    "            try:\n",
    "                # Helpful Constants\n",
    "                yt_link = yt_url_prefix + t\n",
    "\n",
    "                # Download Video\n",
    "                print(f\"Downloading {t}\")\n",
    "                trailer_yt_info = ydl.extract_info(yt_link, download=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed with exception\")\n",
    "                print(e)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_yt_videos(dataset_dir, yt_ids, ydl_opts={}, verbose=False):\n",
    "    ydl_opts['outtmpl'] = dataset_dir + '%(id)s.%(ext)s'\n",
    "    downloaded = os.listdir(dataset_dir)\n",
    "    downloaded = [d.split('.')[0] for d in downloaded]\n",
    "    downloaded = set(downloaded)\n",
    "    all_to_download = set(yt_ids)\n",
    "    remaining_trailers = all_to_download - downloaded\n",
    "    if verbose:\n",
    "        print(f'remaining trailers (len({len(remaining_trailers)})) {remaining_trailers}')\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        for i, t in enumerate(remaining_trailers):\n",
    "            try:\n",
    "                # Helpful Constants\n",
    "                yt_link = yt_url_prefix + t\n",
    "\n",
    "                # Download Video\n",
    "                print(f\"Downloading {t} - {i}/{len(remaining_trailers)}\")\n",
    "                trailer_yt_info = ydl.extract_info(yt_link, download=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed with exception\")\n",
    "                print(e)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_yt_videos(\"../data/\", trailers['trailer_youtube_key'], {'format': 'mp4/bestvideo'}, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Download Casual Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a7JUoSiJG-U',\n",
       " 'W0foraj84oU',\n",
       " 'rtMSMWm-xw0',\n",
       " 'WE5uaL0urok',\n",
       " 'APMcESZjelM',\n",
       " 'FZ7wBmLvcSA',\n",
       " 'Uy6gWBGP9k4',\n",
       " '4hUhAFVpip8',\n",
       " 'tFNT50-fCGk',\n",
       " 'bHKQfui91yc',\n",
       " 'J_EDZOodc14',\n",
       " 'x2irNRNLrrI',\n",
       " 'ggNIcxiUv6Q',\n",
       " 'b9lpQ3P07Ds',\n",
       " 'yAFmSm5l8gE',\n",
       " 'sCFi2O1vyWQ',\n",
       " 'kQM6Q9Axyx0',\n",
       " 'GK2_2dUxtLI',\n",
       " 'O2VSHC9DFbQ',\n",
       " 'I_1oQYpONjs']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./casual_videos.txt\") as f:\n",
    "    casual_yt_ids = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "casual_yt_ids = [l.strip()[-11:] for l in casual_yt_ids if 'https' in l]\n",
    "casual_yt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining trailers (len(6)) {'4hUhAFVpip8', 'tFNT50-fCGk', 'ggNIcxiUv6Q', 'sCFi2O1vyWQ', 'bHKQfui91yc', 'APMcESZjelM'}\n",
      "Downloading 4hUhAFVpip8\n",
      "[youtube] 4hUhAFVpip8: Downloading webpage\n",
      "[youtube] 4hUhAFVpip8: Downloading video info webpage\n",
      "[download] Destination: ../data/casual/4hUhAFVpip8.mp4\n",
      "[download] 100% of 18.11MiB in 00:1709MiB/s ETA 00:000\n",
      "\n",
      "Downloading tFNT50-fCGk\n",
      "[youtube] tFNT50-fCGk: Downloading webpage\n",
      "[youtube] tFNT50-fCGk: Downloading video info webpage\n",
      "[download] Destination: ../data/casual/tFNT50-fCGk.mp4\n",
      "[download] 100% of 105.06MiB in 01:3610MiB/s ETA 00:009\n",
      "\n",
      "Downloading ggNIcxiUv6Q\n",
      "[youtube] ggNIcxiUv6Q: Downloading webpage\n",
      "[youtube] ggNIcxiUv6Q: Downloading video info webpage\n",
      "[youtube] ggNIcxiUv6Q: Downloading js player vflq5GyJR\n",
      "[youtube] ggNIcxiUv6Q: Downloading js player vflq5GyJR\n",
      "[download] Destination: ../data/casual/ggNIcxiUv6Q.mp4\n",
      "[download] 100% of 55.38MiB in 00:5010MiB/s ETA 00:001\n",
      "\n",
      "Downloading sCFi2O1vyWQ\n",
      "[youtube] sCFi2O1vyWQ: Downloading webpage\n",
      "[youtube] sCFi2O1vyWQ: Downloading video info webpage\n",
      "[download] Destination: ../data/casual/sCFi2O1vyWQ.mp4\n",
      "[download] 100% of 110.67MiB in 01:4110MiB/s ETA 00:0051\n",
      "\n",
      "Downloading bHKQfui91yc\n",
      "[youtube] bHKQfui91yc: Downloading webpage\n",
      "[youtube] bHKQfui91yc: Downloading video info webpage\n",
      "[download] Destination: ../data/casual/bHKQfui91yc.mp4\n",
      "[download] 100% of 91.51MiB in 01:2310MiB/s ETA 00:0032\n",
      "\n",
      "Downloading APMcESZjelM\n",
      "[youtube] APMcESZjelM: Downloading webpage\n",
      "[youtube] APMcESZjelM: Downloading video info webpage\n",
      "[download] Destination: ../data/casual/APMcESZjelM.mp4\n",
      "[download] 100% of 162.87MiB in 03:36.12KiB/s ETA 00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_yt_videos(\"../data/casual/\", casual_yt_ids, {'format': 'mp4/bestvideo'}, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Upload Movie Trailers to Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install dependencies\n",
    "#!pip install pandas\n",
    "#!pip install youtube_dl\n",
    "#!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# GOOGLE DRIVE API CONSTANTS\n",
    "flow = InstalledAppFlow.from_client_secrets_file('credentials.json', ['https://www.googleapis.com/auth/drive'])\n",
    "creds = flow.run_local_server(port=0)\n",
    "folder_id = '1UnDIe4VHMM8bZzIfKEG8NJdQGnNrrxEG'\n",
    "drive_api = build('drive', 'v3', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Helpful function\n",
    "def get_file_list_from_folder(service, folder_id):\n",
    "    \"\"\"Print files belonging to a folder.\n",
    "\n",
    "    Args:\n",
    "    service: Drive API service instance.\n",
    "    folder_id: ID of the folder to print files from.\n",
    "    \"\"\"\n",
    "    kwargs = {\n",
    "        \"q\": \"'{}' in parents\".format(folder_id)\n",
    "    }\n",
    "    request = service.files().list(**kwargs)\n",
    "    files = []\n",
    "    while request is not None:\n",
    "        response = request.execute()\n",
    "        # Do stuff with response['files']\n",
    "        files.extend(response['files'])\n",
    "        request = service.files().list_next(request, response)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trailers = pd.read_csv(osp.join(output_folder, \"trailers.csv\"), index_col=0)\n",
    "trailers['movie_title'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ydl_opts = {\n",
    "    'outtmpl': output_folder + '%(id)s.%(ext)s',\n",
    "    'format': 'bestvideo'\n",
    "}\n",
    "\n",
    "uploaded = get_file_list_from_folder(drive_api, folder_id)\n",
    "#print(uploaded)\n",
    "uploaded = [d['name'].split('.')[0] for d in uploaded]\n",
    "duplicates = pd.Series(uploaded).value_counts()\n",
    "uploaded = set(uploaded)\n",
    "#print(duplicates)\n",
    "#print(f'files already uploaded {uploaded}')\n",
    "\n",
    "all_to_download = set(trailers['youtube_key'])\n",
    "#print(f'files already uploaded & requested for upload{uploaded & all_to_download}')\n",
    "remaining_trailers = all_to_download - uploaded\n",
    "print(f'remaining trailers (len({len(remaining_trailers)})) {remaining_trailers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with YoutubeDL(ydl_opts) as ydl:\n",
    "    for t in remaining_trailers:\n",
    "        try:\n",
    "            # Helpful Constants\n",
    "            yt_link = yt_url_prefix + t\n",
    "\n",
    "            # Download Video\n",
    "            print(f\"Downloading {t}\")\n",
    "            trailer_yt_info = ydl.extract_info(yt_link, download=True)\n",
    "            \n",
    "            # Determine File Name\n",
    "            file_name = [f for f in os.listdir(output_folder) if t in f][0]\n",
    "            print(file_name)\n",
    "\n",
    "            # Upload to Drive\n",
    "            print(f\"Uploading file {file_name}...\")\n",
    "            body = {'name': file_name, 'parents': [folder_id]}\n",
    "            media = MediaFileUpload(output_folder + file_name)\n",
    "            fiahl = drive_api.files().create(body=body, media_body=media).execute()\n",
    "            print(f\"Created file '{fiahl.get('name')}' id '{fiahl.get('id')}'.\")\n",
    "\n",
    "            # Delete video from hard drive\n",
    "            os.remove(output_folder + file_name)\n",
    "            print(f\"Removed {file_name}\")\n",
    "            print(\"Success!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed with exception\")\n",
    "            print(e)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
